{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--epoch', type=int, default=0, help='starting epoch\n",
    "\n",
    "--n_epochs', type=int, default=200, help='number of epochs of training\n",
    "\n",
    "--batchSize', type=int, default=10, help='size of the batches\n",
    "\n",
    "--nes', type=str, default='data/nesmbd_tx1', help='root directory of the dataset\n",
    "\n",
    "--lakh', type=str, default='data/5k_poprock_tx1', help='root directory of the dataset\n",
    "\n",
    "--lr', type=float, default=0.0002, help='initial learning rate\n",
    "\n",
    "--decay_epoch', type=int, default=100, help='epoch to start linearly decaying the learning rate to 0\n",
    "\n",
    "--cuda', action='store_true', help='use GPU computation\n",
    "\n",
    "--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=10, cuda=False, decay_epoch=100, epoch=0, lakh='data/5k_poprock_tx1', lr=0.0002, n_cpu=8, n_epochs=200, nes='data/nesmdb_tx1')\n",
      "Producing dataset nesmdb...\n",
      "building vocab from data/nesmdb_tx1/vocab.txt\n",
      "final vocab size 631\n",
      "Loading cached dataset...\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                  | 0/4502 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                          | 6/4502 [00:00<01:43, 43.35it/s]\u001b[A\n",
      "  0%|                                         | 10/4502 [00:00<01:47, 41.84it/s]\u001b[A\n",
      "  0%|                                         | 13/4502 [00:00<02:01, 36.86it/s]\u001b[A\n",
      "  0%|▏                                        | 22/4502 [00:00<02:08, 34.93it/s]\u001b[A\n",
      "  1%|▎                                        | 28/4502 [00:00<02:07, 35.14it/s]\u001b[A\n",
      "  1%|▎                                        | 37/4502 [00:00<01:44, 42.62it/s]\u001b[A\n",
      "  1%|▍                                        | 42/4502 [00:01<01:58, 37.63it/s]\u001b[A\n",
      "  1%|▍                                        | 47/4502 [00:01<02:50, 26.20it/s]\u001b[A\n",
      "  1%|▍                                        | 51/4502 [00:01<04:48, 15.43it/s]\u001b[A\n",
      "  1%|▌                                        | 58/4502 [00:02<03:45, 19.73it/s]\u001b[A\n",
      "  1%|▌                                        | 62/4502 [00:02<03:45, 19.71it/s]\u001b[A\n",
      "  1%|▌                                        | 66/4502 [00:02<03:43, 19.88it/s]\u001b[A\n",
      "  2%|▋                                        | 70/4502 [00:02<03:40, 20.11it/s]\u001b[A\n",
      "  2%|▋                                        | 73/4502 [00:02<03:45, 19.64it/s]\u001b[A\n",
      "  2%|▋                                        | 76/4502 [00:02<03:51, 19.09it/s]\u001b[A\n",
      "  2%|▋                                        | 79/4502 [00:03<03:38, 20.20it/s]\u001b[A\n",
      "  2%|▊                                        | 88/4502 [00:03<02:48, 26.20it/s]\u001b[A\n",
      "  2%|▊                                        | 93/4502 [00:03<02:50, 25.84it/s]\u001b[A\n",
      "  2%|▉                                        | 97/4502 [00:03<02:54, 25.17it/s]\u001b[A\n",
      "  2%|▉                                       | 101/4502 [00:04<05:05, 14.40it/s]\u001b[A\n",
      "  2%|▉                                       | 106/4502 [00:04<04:13, 17.36it/s]\u001b[A\n",
      "  2%|▉                                       | 109/4502 [00:04<05:47, 12.64it/s]\u001b[A\n",
      "  3%|█                                       | 114/4502 [00:04<04:37, 15.82it/s]\u001b[A\n",
      "  3%|█                                       | 119/4502 [00:04<03:51, 18.91it/s]\u001b[A\n",
      "  3%|█                                       | 124/4502 [00:05<03:20, 21.81it/s]\u001b[A\n",
      "  3%|█▏                                      | 128/4502 [00:05<03:30, 20.80it/s]\u001b[A\n",
      "  3%|█▏                                      | 132/4502 [00:05<03:00, 24.22it/s]\u001b[A\n",
      "  3%|█▏                                      | 136/4502 [00:05<02:45, 26.32it/s]\u001b[A\n",
      "  3%|█▎                                      | 143/4502 [00:05<02:17, 31.67it/s]\u001b[A\n",
      "  3%|█▎                                      | 152/4502 [00:05<01:51, 39.14it/s]\u001b[A\n",
      "  4%|█▍                                      | 158/4502 [00:05<02:01, 35.66it/s]\u001b[A\n",
      "  4%|█▍                                      | 163/4502 [00:06<02:02, 35.53it/s]\u001b[A\n",
      "  4%|█▍                                      | 168/4502 [00:06<02:15, 32.10it/s]\u001b[A\n",
      "  4%|█▌                                      | 172/4502 [00:06<03:22, 21.35it/s]\u001b[A\n",
      "  4%|█▌                                      | 176/4502 [00:06<03:35, 20.09it/s]\u001b[A\n",
      "  4%|█▋                                      | 184/4502 [00:06<02:48, 25.57it/s]\u001b[A\n",
      "  4%|█▋                                      | 193/4502 [00:07<02:32, 28.30it/s]\u001b[A\n",
      "  4%|█▊                                      | 197/4502 [00:07<03:52, 18.51it/s]\u001b[A\n",
      "  4%|█▊                                      | 201/4502 [00:07<03:49, 18.76it/s]\u001b[A\n",
      "  5%|█▊                                      | 205/4502 [00:07<03:13, 22.16it/s]\u001b[A\n",
      "  5%|█▊                                      | 209/4502 [00:08<04:20, 16.48it/s]\u001b[A\n",
      "  5%|█▉                                      | 215/4502 [00:08<03:29, 20.48it/s]\u001b[A^C\n",
      "  5%|█▉                                      | 219/4502 [00:08<02:46, 25.76it/s]\n",
      "0it [00:08, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 85, in <module>\n",
      "    for i, ((nes, bptt), (lakh, _)) in enumerate(tqdm(data_stream)):\n",
      "  File \"/Users/dima/.local/lib/python3.7/site-packages/tqdm/std.py\", line 1171, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/data_utils.py\", line 187, in __iter__\n",
      "    trim_padding=self.trim_padding))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 144, in encode_file\n",
      "    encoded.append(self.convert_to_tensor(symbols))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 220, in convert_to_tensor\n",
      "    return torch.LongTensor(self.get_indices(symbols))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 217, in get_indices\n",
      "    return [self.get_idx(sym) for sym in symbols]\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 217, in <listcomp>\n",
      "    return [self.get_idx(sym) for sym in symbols]\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 206, in get_idx\n",
      "    closest = min(self.wait_amts, key=lambda x:abs(x - wait_amt))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 206, in <lambda>\n",
      "    closest = min(self.wait_amts, key=lambda x:abs(x - wait_amt))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAz6GBJ5du8jjwgmfIUkFB",
   "collapsed_sections": [],
   "mount_file_id": "1NfLtkWYkw5zAiMJwORTyoCimGjFStxu7",
   "name": "InitialTesting.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
