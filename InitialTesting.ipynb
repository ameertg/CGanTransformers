{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--epoch', type=int, default=0, help='starting epoch\n",
    "\n",
    "--n_epochs', type=int, default=200, help='number of epochs of training\n",
    "\n",
    "--batchSize', type=int, default=10, help='size of the batches\n",
    "\n",
    "--nes', type=str, default='data/nesmbd_tx1', help='root directory of the dataset\n",
    "\n",
    "--lakh', type=str, default='data/5k_poprock_tx1', help='root directory of the dataset\n",
    "\n",
    "--lr', type=float, default=0.0002, help='initial learning rate\n",
    "\n",
    "--decay_epoch', type=int, default=100, help='epoch to start linearly decaying the learning rate to 0\n",
    "\n",
    "--cuda', action='store_true', help='use GPU computation\n",
    "\n",
    "--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=10, cuda=False, decay_epoch=100, epoch=0, lakh='data/5k_poprock_tx1', lr=0.0002, n_cpu=8, n_epochs=200, nes='data/nesmdb_tx1')\n",
      "Producing dataset nesmdb...\n",
      "building vocab from data/nesmdb_tx1/vocab.txt\n",
      "final vocab size 631\n",
      "Loading cached dataset...\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                  | 0/4502 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                          | 6/4502 [00:00<01:43, 43.35it/s]\u001b[A\n",
      "  0%|                                         | 10/4502 [00:00<01:47, 41.84it/s]\u001b[A\n",
      "  0%|                                         | 13/4502 [00:00<02:01, 36.86it/s]\u001b[A\n",
      "  0%|▏                                        | 22/4502 [00:00<02:08, 34.93it/s]\u001b[A\n",
      "  1%|▎                                        | 28/4502 [00:00<02:07, 35.14it/s]\u001b[A\n",
      "  1%|▎                                        | 37/4502 [00:00<01:44, 42.62it/s]\u001b[A\n",
      "  1%|▍                                        | 42/4502 [00:01<01:58, 37.63it/s]\u001b[A\n",
      "  1%|▍                                        | 47/4502 [00:01<02:50, 26.20it/s]\u001b[A\n",
      "  1%|▍                                        | 51/4502 [00:01<04:48, 15.43it/s]\u001b[A\n",
      "  1%|▌                                        | 58/4502 [00:02<03:45, 19.73it/s]\u001b[A\n",
      "  1%|▌                                        | 62/4502 [00:02<03:45, 19.71it/s]\u001b[A\n",
      "  1%|▌                                        | 66/4502 [00:02<03:43, 19.88it/s]\u001b[A\n",
      "  2%|▋                                        | 70/4502 [00:02<03:40, 20.11it/s]\u001b[A\n",
      "  2%|▋                                        | 73/4502 [00:02<03:45, 19.64it/s]\u001b[A\n",
      "  2%|▋                                        | 76/4502 [00:02<03:51, 19.09it/s]\u001b[A\n",
      "  2%|▋                                        | 79/4502 [00:03<03:38, 20.20it/s]\u001b[A\n",
      "  2%|▊                                        | 88/4502 [00:03<02:48, 26.20it/s]\u001b[A\n",
      "  2%|▊                                        | 93/4502 [00:03<02:50, 25.84it/s]\u001b[A\n",
      "  2%|▉                                        | 97/4502 [00:03<02:54, 25.17it/s]\u001b[A\n",
      "  2%|▉                                       | 101/4502 [00:04<05:05, 14.40it/s]\u001b[A\n",
      "  2%|▉                                       | 106/4502 [00:04<04:13, 17.36it/s]\u001b[A\n",
      "  2%|▉                                       | 109/4502 [00:04<05:47, 12.64it/s]\u001b[A\n",
      "  3%|█                                       | 114/4502 [00:04<04:37, 15.82it/s]\u001b[A\n",
      "  3%|█                                       | 119/4502 [00:04<03:51, 18.91it/s]\u001b[A\n",
      "  3%|█                                       | 124/4502 [00:05<03:20, 21.81it/s]\u001b[A\n",
      "  3%|█▏                                      | 128/4502 [00:05<03:30, 20.80it/s]\u001b[A\n",
      "  3%|█▏                                      | 132/4502 [00:05<03:00, 24.22it/s]\u001b[A\n",
      "  3%|█▏                                      | 136/4502 [00:05<02:45, 26.32it/s]\u001b[A\n",
      "  3%|█▎                                      | 143/4502 [00:05<02:17, 31.67it/s]\u001b[A\n",
      "  3%|█▎                                      | 152/4502 [00:05<01:51, 39.14it/s]\u001b[A\n",
      "  4%|█▍                                      | 158/4502 [00:05<02:01, 35.66it/s]\u001b[A\n",
      "  4%|█▍                                      | 163/4502 [00:06<02:02, 35.53it/s]\u001b[A\n",
      "  4%|█▍                                      | 168/4502 [00:06<02:15, 32.10it/s]\u001b[A\n",
      "  4%|█▌                                      | 172/4502 [00:06<03:22, 21.35it/s]\u001b[A\n",
      "  4%|█▌                                      | 176/4502 [00:06<03:35, 20.09it/s]\u001b[A\n",
      "  4%|█▋                                      | 184/4502 [00:06<02:48, 25.57it/s]\u001b[A\n",
      "  4%|█▋                                      | 193/4502 [00:07<02:32, 28.30it/s]\u001b[A\n",
      "  4%|█▊                                      | 197/4502 [00:07<03:52, 18.51it/s]\u001b[A\n",
      "  4%|█▊                                      | 201/4502 [00:07<03:49, 18.76it/s]\u001b[A\n",
      "  5%|█▊                                      | 205/4502 [00:07<03:13, 22.16it/s]\u001b[A\n",
      "  5%|█▊                                      | 209/4502 [00:08<04:20, 16.48it/s]\u001b[A\n",
      "  5%|█▉                                      | 215/4502 [00:08<03:29, 20.48it/s]\u001b[A^C\n",
      "  5%|█▉                                      | 219/4502 [00:08<02:46, 25.76it/s]\n",
      "0it [00:08, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 85, in <module>\n",
      "    for i, ((nes, bptt), (lakh, _)) in enumerate(tqdm(data_stream)):\n",
      "  File \"/Users/dima/.local/lib/python3.7/site-packages/tqdm/std.py\", line 1171, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/data_utils.py\", line 187, in __iter__\n",
      "    trim_padding=self.trim_padding))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 144, in encode_file\n",
      "    encoded.append(self.convert_to_tensor(symbols))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 220, in convert_to_tensor\n",
      "    return torch.LongTensor(self.get_indices(symbols))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 217, in get_indices\n",
      "    return [self.get_idx(sym) for sym in symbols]\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 217, in <listcomp>\n",
      "    return [self.get_idx(sym) for sym in symbols]\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 206, in get_idx\n",
      "    closest = min(self.wait_amts, key=lambda x:abs(x - wait_amt))\n",
      "  File \"/Users/dima/Documents/Github/CGanTransformers/utils/vocabulary.py\", line 206, in <lambda>\n",
      "    closest = min(self.wait_amts, key=lambda x:abs(x - wait_amt))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Hot to Mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import Generator\n",
    "import numpy as np\n",
    "from data.tx1_midi import tx1_to_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('output/fullModel_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nin_dims = 80\n",
    "netG_A2B = Generator(nin_dims)\n",
    "netG_A2B.load_state_dict(checkpoint['genBA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.random.randint(631,size=(40,1)).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 80\n",
    "test_one_hot = np.eye(631)[np.random.choice(631, 80)]\n",
    "test_one_hot = torch.tensor(test_one_hot.reshape((40,2,631)).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq length, batch, 1hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = netG_A2B.forward(test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(out,\"test_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('data/tx1_vocab.txt','r') as f:\n",
    "    tokens = f.readlines()\n",
    "    print(type(tokens[0]))\n",
    "    tokens = [tok.strip('\\n') for tok in tokens]\n",
    "    idx2tok = {i:tokens[i-1] for i in range(1,631)}\n",
    "idx2tok[0] = 'WT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot_TX1(one_hot):\n",
    "    argm = np.argmax(out.detach().numpy(),axis=2)\n",
    "    batch_size = argm.shape[1]\n",
    "    outputs = []\n",
    "    for b in range(batch_size):\n",
    "        toks = [idx2tok[int(i)] for i in argm[:,b]]\n",
    "        outputs.append(\"\\n\".join(toks))\n",
    "    return outputs\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WT_2900\\nWT_3700\\nWT_52000\\nTR_NOTEON_48\\nWT_370\\nNO_NOTEON_8\\nWT_2900\\nWT_4400\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_2900\\nP2_NOTEON_33\\nWT_2900\\nWT_2900\\nNO_NOTEOFF\\nTR_NOTEON_63\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_1\\nWT_2200\\nWT_2900\\nWT_2900\\nWT_1400\\nWT_2900\\nWT_4400\\nP1_NOTEON_90\\nP2_NOTEOFF\\nWT_2900\\nTR_NOTEON_100\\nWT_1400\\nP2_NOTEOFF\\nWT_1000\\nWT_2900\\nTR_NOTEOFF',\n",
       " 'WT_2900\\nWT_2900\\nWT_740\\nWT_590\\nP2_NOTEON_103\\nWT_2900\\nWT_2900\\nP2_NOTEON_39\\nWT_96\\nWT_2900\\nWT_2900\\nWT_2900\\nTR_NOTEON_65\\nWT_600\\nWT_870\\nWT_460\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_2900\\nWT_1\\nTR_NOTEON_96\\nWT_730\\nNO_NOTEON_13\\nWT_3700\\nP1_NOTEON_55\\nWT_2900\\nWT_63000\\nWT_2900\\nWT_10\\nTR_NOTEOFF\\nWT_2900\\nWT_2900\\nNO_NOTEON_13\\nWT_2900\\nWT_2900\\nWT_2900\\nP2_NOTEON_85\\nWT_2900\\nWT_47']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHot_TX1(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "argm = np.argmax(out.detach().numpy(),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([209, 209, 164, 149, 519, 209, 209, 455,  96, 209, 209, 209, 570,\n",
       "       150, 177, 136, 209, 209, 209, 209,   1, 601, 163, 627, 217, 394,\n",
       "       209, 333, 209,  10, 525, 209, 209, 627, 209, 209, 209, 501, 209,\n",
       "        47])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argm[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "aye = ['a','b','c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(aye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'MThd\\x00\\x00\\x00\\x06\\x00\\x01\\x00\\x05V\"MTrk\\x00\\x00\\x00\\x1d\\x00\\xffQ\\x03\\x07\\xa1 \\x00\\xffX\\x04\\x04\\x02\\x18\\x08\\x87\\xeeg\\xffX\\x04\\x01\\x00\\x18\\x08\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\r\\x00\\xff\\x03\\x02p1\\x00\\xc0P\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x18\\x00\\xff\\x03\\x02p2\\x00\\xc1Q\\x85\\x8dV\\x91!\\x0f\\x82\\xa1\\t!\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\'\\x00\\xff\\x03\\x02tr\\x00\\xc2&\\x83\\xc9h\\x920\\x01\\x81\\xf1\\x160\\x00\\x00?\\x01\\x82\\x8a5?\\x00\\x00d\\x01\\xa94d\\x00\\x01\\xff/\\x00MTrk\\x00\\x00\\x00\\x18\\x00\\xff\\x03\\x02no\\x00\\xc9y\\x83\\xccZ\\x99\\x08\\x0f\\x81\\xee$\\x08\\x00\\x01\\xff/\\x00'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx1_to_midi(oneHot_TX1(out)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tx1 to Mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.tx1_midi import tx1_to_midi\n",
    "fpathNoPerms = 'data/5k_poprock_tx1_noPerms/test/0a4f2051b572ebe007647fcab0114dd8_000.txt'\n",
    "fpathPerms = 'data/5k_poprock_tx1/test/6e973cb0ce78fb872d9bbb9916c69f40_000.txt'\n",
    "with open(fpathNoPerms,'r') as f:\n",
    "    tx1 = f.read()\n",
    "mid = tx1_to_midi(tx1)\n",
    "mid.write('data/test_tx1_mid_in/no1hotNoPerm.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid.write(\"lol.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAz6GBJ5du8jjwgmfIUkFB",
   "collapsed_sections": [],
   "mount_file_id": "1NfLtkWYkw5zAiMJwORTyoCimGjFStxu7",
   "name": "InitialTesting.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
